{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "female-cyprus",
   "metadata": {},
   "source": [
    "# WALLABY Catalgoue Management\n",
    "\n",
    "In this notebook we go through a WALLABY administrator workflow to demonstrate how these notebooks can be used for managing the content of the catalogue. This notebook will have write access to the WALLABY database, but will require an authorised user.\n",
    "\n",
    "We will go through two main workflows: the development of duplicate detection algorithms that can be included in `SoFiAX` or to be included as part of future WALLABY workflows in RADEC, and performing manual inspection of detections.\n",
    "\n",
    "\n",
    "### A. Development of SoFiAX duplicate algorithms\n",
    "\n",
    "These notebooks can provide a useful workspace to iterate and develop new algorithms for identifying duplicate detections. These can then be added to SoFiAX (or to a source finding pipeline) when complete. The duplicates identified by this new algorithm can then be investigated manually without writing to the database, and can be managed completely in this notebook.\n",
    "\n",
    "We will do the following to demonstrate this:\n",
    "\n",
    "1. Develop a simple algorithm for identifying duplicates\n",
    "2. Verify the algorithm creates the tags we expect.\n",
    "3. Retrieve objects based on tags.\n",
    "\n",
    "### B. Manual inspection for components\n",
    "\n",
    "Manual inspection and management of components can be done as a final step (after automated processes that are implemented in SoFiAX) in this notebook. A WALLABY administrator who identifies two or more detections that are actually a single source can tag, merge and re-run SoFiA and SoFiAX (assuming the cube size is small) in this notebook.\n",
    "\n",
    "1. Perform some visual inspection and tag detections\n",
    "2. Re-run SoFiA after identifying components of the same galaxy\n",
    "3. Re-run SoFiAX to generate outputs for this new source\n",
    "4. Delete components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-costume",
   "metadata": {},
   "source": [
    "# Import libraries + setup Django\n",
    "\n",
    "Starting point of every notebook that accesses Django models. Run the three cells below to import libraries/modules and setup Django."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import django\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Django shell\n",
    "\n",
    "sys.path.append('SoFiAX_services/api/')\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"]=\"True\"\n",
    "os.environ[\"DJANGO_SETTINGS_MODULE\"] = \"api.settings\"\n",
    "os.environ[\"DJANGO_DATABASE_NAME\"]=\"sofiadb\"\n",
    "os.environ[\"DJANGO_DATABASE_USER\"]=\"admin\"\n",
    "os.environ[\"DJANGO_DATABASE_PASSWORD\"]=\"admin\"\n",
    "os.environ[\"DJANGO_DATABASE_HOST\"]=\"146.118.69.90\"\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Django models\n",
    "\n",
    "from run.models import Run\n",
    "from instance.models import Instance\n",
    "from detection.models import Detection\n",
    "from products.models import Products\n",
    "\n",
    "from sources.models import Sources\n",
    "from comments.models import Comments\n",
    "from tag.models import Tag, TagDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-width",
   "metadata": {},
   "source": [
    "# Develop SoFiAX duplicate detection algorithm\n",
    "\n",
    "We're going to go through the process of developing a very simple duplicate identification algorithm for detections in the database. This naive approach will just look at the position, flux (sum) and position angle similarity between any pair of detections. This algorithm is applied to all pairs of detections in our database, and if the differences are below some threshold for each property, we will visually inspect them and tag if appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-journalist",
   "metadata": {},
   "source": [
    "Let's implement this naive duplicate identification algorithm and then apply it on all pairs of detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that we can test on pairs\n",
    "\n",
    "def identify_duplicate(d1, d2):\n",
    "    \"\"\"Simple and naive duplicate detection algorithm. Can\n",
    "    update threshold values as necessary.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Threshold values\n",
    "    pos_threshold = 10\n",
    "    flux_threshold = 5\n",
    "    kin_pa_threshold = 5\n",
    "    \n",
    "    # Compute differences between detections\n",
    "    pos_diff = np.linalg.norm(\n",
    "        np.array([d1.x, d1.y, d1.z]) - np.array([d2.x, d2.y, d2.z])\n",
    "    )\n",
    "    flux_diff = np.abs(d1.f_sum - d2.f_sum)\n",
    "    kin_pa_diff = np.abs(d1.kin_pa - d2.kin_pa)\n",
    "    \n",
    "    # Duplicate logic\n",
    "    if (pos_diff <= pos_threshold) & (flux_diff <= flux_threshold) & (kin_pa_diff <= kin_pa_threshold):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function on each pair of detections. Let's also filter\n",
    "# out the detections that have the same name.\n",
    "\n",
    "detections = Detection.objects.all()\n",
    "N_detections = len(detections)\n",
    "\n",
    "detection_pair_ids = []\n",
    "\n",
    "for i in range(N_detections):\n",
    "    for j in range(i + 1, N_detections):\n",
    "        d1 = detections[i]\n",
    "        d2 = detections[j]\n",
    "        if identify_duplicate(d1, d2):\n",
    "            pair = (d1.id, d2.id)\n",
    "            detection_pair_ids.append(pair)\n",
    "            print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-gather",
   "metadata": {},
   "source": [
    "We have returned the `id`s for the detections that meet the duplicate identification function criteria and do not have the same name. We could automatically tag these (in the body of the function or as we apply them to pairs of detections). But we could also just inspect them now in the notebook.\n",
    "\n",
    "**NOTE**: the filter for name should be included in the original function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-hughes",
   "metadata": {},
   "source": [
    "## Visualisation \n",
    "\n",
    "Tobias has provided a new plotting script that we will use to compare these pairs of sources. Users should feel free to change the content of the cells below and install other libraries they would like to use for their own visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import io\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import PercentileInterval\n",
    "from astroquery.skyview import SkyView\n",
    "from astropy.utils.data import clear_download_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "Products._meta.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for generating plots for inspecting detections\n",
    "\n",
    "def retrieve_dss_image(longitude, latitude, width, height):\n",
    "    hdulist = SkyView.get_images(position=\"{}, {}\".format(longitude, latitude), survey=[\"DSS\"], coordinates=\"J2000\", projection=\"Tan\", pixels=\"{}, {}\".format(str(int(2400 * width)), str(int(2400 * height))), width=width*u.deg, height=height*u.deg);\n",
    "    return hdulist[0][0]\n",
    "\n",
    "def inspect_plot(detection):\n",
    "    # Plot figure size    \n",
    "    interval = PercentileInterval(95.0)\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "    \n",
    "    # Retrieve products from database\n",
    "    products = Products.objects.get(detection=detection)\n",
    "    \n",
    "    # Open moment 0 image\n",
    "    with io.BytesIO() as buf:\n",
    "        buf.write(products.moment0)\n",
    "        buf.seek(0)\n",
    "        hdu_mom0 = fits.open(buf)[0]\n",
    "        wcs = WCS(hdu_mom0.header)\n",
    "        mom0 = hdu_mom0.data\n",
    "\n",
    "    # Open moment 1 image\n",
    "    with io.BytesIO() as buf:\n",
    "        buf.write(products.moment1)\n",
    "        buf.seek(0)\n",
    "        hdu_mom1 = fits.open(buf)[0]\n",
    "        mom1 = hdu_mom1.data\n",
    "\n",
    "    with io.BytesIO() as buf:\n",
    "        buf.write(b''.join(products.spectrum))\n",
    "        buf.seek(0)\n",
    "        spectrum = np.loadtxt(buf, dtype=\"float\", comments=\"#\", unpack=True)\n",
    "\n",
    "    # Extract coordinate information\n",
    "    nx = hdu_mom0.header[\"NAXIS1\"]\n",
    "    ny = hdu_mom0.header[\"NAXIS2\"]\n",
    "    clon, clat = wcs.all_pix2world(nx/2, ny/2, 0)\n",
    "    tmp1, tmp3 = wcs.all_pix2world(0, ny/2, 0)\n",
    "    tmp2, tmp4 = wcs.all_pix2world(nx, ny/2, 0)\n",
    "    width = np.rad2deg(math.acos(math.sin(np.deg2rad(tmp3)) * math.sin(np.deg2rad(tmp4)) + math.cos(np.deg2rad(tmp3)) * math.cos(np.deg2rad(tmp4)) * math.cos(np.deg2rad(tmp1 - tmp2))))\n",
    "    tmp1, tmp3 = wcs.all_pix2world(nx/2, 0, 0)\n",
    "    tmp2, tmp4 = wcs.all_pix2world(nx/2, ny, 0)\n",
    "    height = np.rad2deg(math.acos(math.sin(np.deg2rad(tmp3)) * math.sin(np.deg2rad(tmp4)) + math.cos(np.deg2rad(tmp3)) * math.cos(np.deg2rad(tmp4)) * math.cos(np.deg2rad(tmp1 - tmp2))))\n",
    "    \n",
    "    # Download DSS image from SkyView\n",
    "    hdu_opt = retrieve_dss_image(clon, clat, width, height)\n",
    "    wcs_opt = WCS(hdu_opt.header)\n",
    "    \n",
    "    # Plot moment 0\n",
    "    ax2 = plt.subplot(2, 2, 1, projection=wcs);\n",
    "    ax2.imshow(mom0, origin=\"lower\");\n",
    "    ax2.grid(color=\"grey\", ls=\"solid\");\n",
    "    ax2.set_xlabel(\"Right ascension (J2000)\");\n",
    "    ax2.set_ylabel(\"Declination (J2000)\");\n",
    "    ax2.tick_params(axis=\"x\", which=\"both\", left=False, right=False);\n",
    "    ax2.tick_params(axis=\"y\", which=\"both\", top=False, bottom=False);\n",
    "    ax2.set_title(\"moment 0\");\n",
    "\n",
    "    # Plot DSS image with HI contours\n",
    "    bmin, bmax = interval.get_limits(hdu_opt.data);\n",
    "    ax = plt.subplot(2, 2, 2, projection=wcs_opt);\n",
    "    ax.imshow(hdu_opt.data, origin=\"lower\");\n",
    "    ax.contour(hdu_mom0.data, transform=ax.get_transform(wcs), levels=np.logspace(2.0, 5.0, 10), colors=\"lightgrey\", alpha=1.0);\n",
    "    ax.grid(color=\"grey\", ls=\"solid\");\n",
    "    ax.set_xlabel(\"Right ascension (J2000)\");\n",
    "    ax.set_ylabel(\"Declination (J2000)\");\n",
    "    ax.tick_params(axis=\"x\", which=\"both\", left=False, right=False);\n",
    "    ax.tick_params(axis=\"y\", which=\"both\", top=False, bottom=False);\n",
    "    ax.set_title(\"DSS + moment 0\");\n",
    "\n",
    "    # Plot moment 1\n",
    "    bmin, bmax = interval.get_limits(mom1);\n",
    "    ax3 = plt.subplot(2, 2, 3, projection=wcs);\n",
    "    ax3.imshow(hdu_mom1.data, origin=\"lower\", vmin=bmin, vmax=bmax, cmap=plt.get_cmap(\"gist_rainbow\"));\n",
    "    ax3.grid(color=\"grey\", ls=\"solid\");\n",
    "    ax3.set_xlabel(\"Right ascension (J2000)\");\n",
    "    ax3.set_ylabel(\"Declination (J2000)\");\n",
    "    ax3.tick_params(axis=\"x\", which=\"both\", left=False, right=False);\n",
    "    ax3.tick_params(axis=\"y\", which=\"both\", top=False, bottom=False);\n",
    "    ax3.set_title(\"moment 1\");\n",
    "\n",
    "    # Plot spectrum\n",
    "    xaxis = spectrum[1] / 1e+6;\n",
    "    data  = 1000.0 * np.nan_to_num(spectrum[2]);\n",
    "    xmin = np.nanmin(xaxis);\n",
    "    xmax = np.nanmax(xaxis);\n",
    "    ymin = np.nanmin(data);\n",
    "    ymax = np.nanmax(data);\n",
    "    ymin -= 0.1 * (ymax - ymin);\n",
    "    ymax += 0.1 * (ymax - ymin);\n",
    "    ax4 = plt.subplot(2, 2, 4);\n",
    "    ax4.step(xaxis, data, where=\"mid\", color=\"royalblue\");\n",
    "    ax4.set_xlabel(\"Frequency (MHz)\");\n",
    "    ax4.set_ylabel(\"Flux density (mJy)\");\n",
    "    ax4.set_title(\"spectrum\");\n",
    "    ax4.grid(True);\n",
    "    ax4.set_xlim([xmin, xmax]);\n",
    "    ax4.set_ylim([ymin, ymax]);\n",
    "\n",
    "    plt.suptitle(detection.name.replace(\"_\", \" \").replace(\"-\", \"−\"), fontsize=16);\n",
    "    plt.show();\n",
    "\n",
    "    # Clean up\n",
    "    clear_download_cache(pkgname=\"astroquery\");\n",
    "    clear_download_cache();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-remainder",
   "metadata": {},
   "source": [
    "Now that we have the ability to generate plots for comparing, let's do a comparison of a detection with a known mock detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect plots for detection objects.\n",
    "\n",
    "detection1 = Detection.objects.get(id=3603)\n",
    "detection2 = Detection.objects.get(id=4261)\n",
    "\n",
    "inspect_plot(detection1)\n",
    "inspect_plot(detection2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-contemporary",
   "metadata": {},
   "source": [
    "These are duplicates and we know that because they have the same name in the database. Let's leave a tag on one of the detections so that we can refer back to it later (once we figure out what to do with it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tag for this duplicate\n",
    "\n",
    "tag_name = \"Manual inspect duplicate J164455-575029\"\n",
    "if Tag.objects.filter(tag_name=tag_name).exists():\n",
    "    tag = tag = Tag.objects.get(tag_name=tag_name)\n",
    "else:\n",
    "    tag = Tag.objects.get(tag_name=tag_name, added_at=datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign tag to these detections\n",
    "\n",
    "TagDetection.objects.create(tag=tag, detection=detection1)\n",
    "TagDetection.objects.create(tag=tag, detection=detection2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_detections = [d.detection for d in TagDetection.objects.all()]\n",
    "print(tagged_detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-decrease",
   "metadata": {},
   "source": [
    "Great! We see the tags that we have added for this pair of detections. If you see more it's becuase we've run the same cell multiple times (no harm done we can delete `TagDetection` objects easily. We have developed an algorithm that can identify and tag detections in the database. This can be included as part of SoFiAX or as part of a WALLABY source finding workflow in RADEC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-geography",
   "metadata": {},
   "source": [
    "# Manual inspection for components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-paintball",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
